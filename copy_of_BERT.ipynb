{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iyersamridhi/NewsScraping/blob/main/copy_of_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjqnke_LTQ9S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39b1529c-70e6-4dd1-fd7c-48831015511e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 6.1 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 62.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 76.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (2.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (57.4.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 70.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (14.0.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (21.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (0.28.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.21.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (3.19.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (4.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.14.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (5.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (2022.12.7)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow_text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.8/dist-packages (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (3.19.6)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow_hub) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow_text \n",
        "!pip install tensorflow_hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "Av2ch2u-ZNkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "encoder_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
      ],
      "metadata": {
        "id": "TwLcTfPYbGys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(preprocess_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUkJvUTrbJVg",
        "outputId": "89edea5a-b3d9-42ce-f64f-e56a54e8cb23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['nice movie indeed','I love python programming']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "text_preprocessed.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGxx0sXIfvxM",
        "outputId": "f971ee39-886a-4483-8d5f-ab3ae0cc0c7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_word_ids', 'input_mask', 'input_type_ids'])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed['input_mask']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2S6pmGkhF9f",
        "outputId": "332f0aaa-d377-41eb-c3a6-511e08af9d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 128), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]],\n",
              "      dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing our final scraped dataset\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('final_data.csv')"
      ],
      "metadata": {
        "id": "o_mjO377hIK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df.head()\n",
        "#df.head(20)\n",
        "print(df.iloc[2])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmC0JaYfhpfG",
        "outputId": "2260e166-d884-477a-ccee-fa7f7d83134d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unnamed: 0                                                      2\n",
            "Unnamed: 0.1                                                  2.0\n",
            "title           A God of War TV show is officially coming to A...\n",
            "description     Amazon’s rumored God of War Prime Video show h...\n",
            "url             https://www.theverge.com/2022/12/14/23509418/g...\n",
            "index                                                           2\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = df['title']\n",
        "a = a.to_list()"
      ],
      "metadata": {
        "id": "aqRTVUVph2EE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_preprocessed = bert_preprocess_model(a)"
      ],
      "metadata": {
        "id": "atFO_FkciUYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(encoder_url)"
      ],
      "metadata": {
        "id": "AYisE8Nkir3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)"
      ],
      "metadata": {
        "id": "5XOFTGCMolRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import pairwise\n",
        "def plot_similarity(features, labels):\n",
        "  \"\"\"Plot a similarity matrix of the embeddings.\"\"\"\n",
        "  cos_sim = pairwise.cosine_similarity(features)\n",
        "  sns.set(font_scale=1.2)\n",
        "  cbar_kws=dict(use_gridspec=False, location=\"left\")\n",
        "  g = sns.heatmap(\n",
        "      cos_sim, xticklabels=labels, yticklabels=labels,\n",
        "      vmin=0, vmax=1, cmap=\"Blues\", cbar_kws=cbar_kws)\n",
        "  g.tick_params(labelright=True, labelleft=False)\n",
        "  g.set_yticklabels(labels, rotation=0)\n",
        "  g.set_title(\"Semantic Textual Similarity\")\n"
      ],
      "metadata": {
        "id": "G6jPgxKomnmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim = pairwise.cosine_similarity(bert_results['pooled_output'])\n",
        "len(cos_sim)\n",
        "print(type(cos_sim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vdS-16sndc0",
        "outputId": "c629f675-9e83-4f12-b787-0b43d36af170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Nqv55roa57",
        "outputId": "d1a9ce6d-4fbe-40e8-d616-860d40c43b61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1284, 1284)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cos_sim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NimRlV5UozKM",
        "outputId": "3cc461e4-6818-4f16-e62a-b539a7be090c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000002 , 0.9404485 , 0.9805989 , ..., 0.9414948 , 0.8054834 ,\n",
              "        0.927897  ],\n",
              "       [0.9404485 , 1.        , 0.9493502 , ..., 0.99546057, 0.629422  ,\n",
              "        0.9855678 ],\n",
              "       [0.9805989 , 0.9493502 , 1.        , ..., 0.948518  , 0.79784065,\n",
              "        0.9391405 ],\n",
              "       ...,\n",
              "       [0.9414948 , 0.99546057, 0.948518  , ..., 0.99999976, 0.6283771 ,\n",
              "        0.98286283],\n",
              "       [0.8054834 , 0.629422  , 0.79784065, ..., 0.6283771 , 0.99999976,\n",
              "        0.65380824],\n",
              "       [0.927897  , 0.9855678 , 0.9391405 , ..., 0.98286283, 0.65380824,\n",
              "        0.99999994]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "similarity_df = pd.DataFrame() \n",
        "similarity_df = pd.DataFrame(cos_sim)\n",
        "#print(similarity_df)\n",
        "#print(type(similarity_df))\n",
        "# set multi-index\n",
        "similarity_df['index'] = np.arange(similarity_df.shape[0])\n",
        "similarity_df\n",
        "#similarity_df[similarity_df[\"0\"] ==  0.85\n"
      ],
      "metadata": {
        "id": "_QiIuQl8o3JP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8ea3835-4e0d-4692-9121-e44dbe92c38e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       0.981493\n",
              "1       0.958959\n",
              "2       0.975151\n",
              "3       0.951359\n",
              "4       0.808141\n",
              "          ...   \n",
              "1279    0.976451\n",
              "1280    0.976649\n",
              "1281    0.953347\n",
              "1282    0.784351\n",
              "1283    0.948341\n",
              "Name: 9, Length: 1284, dtype: float32"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dicts = {}\n",
        "keys = range(300)\n",
        "for i in range(300):\n",
        "  #threshold_df = similarity_df[similarity_df[i] > 0.92]\n",
        "  #threshold_df = similarity_df[similarity_df[i] > 0.85 & similarity_df[i] <0.93]\n",
        "  threshold_df = similarity_df[similarity_df[i].between(0.85, 0.92)]\n",
        "\n",
        "  #threshold_df= similarity_df[(similarity_df[similarity_df[i] > 0.85]) & (similarity_df[i] < 0.93)]\n",
        "\n",
        "  for i in keys:\n",
        "        dicts[i] =  threshold_list = threshold_df['index'].tolist()\n",
        "print(dicts)\n",
        "print(len(dicts[0]))\n",
        "#for key,values in dicts.items():\n",
        "     #for v in values:\n",
        "          #print(key,\" : \",v)\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KH7RkOXTgd4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(user_1)):\n",
        "  post_id=user_1[i]\n",
        "  #dicts[post_id]\n",
        "  dicts[post_id] = threshold_list 1 \n",
        "  #print(threshold_list)\n",
        "  for j in range(len(threshold_list)):\n",
        "    #print(len(threshold_list))\n",
        "    #threshold_item = threshold_list[j]\n",
        "    print(df.iloc[threshold_list[j]])\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l57eBHuMDqIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nENnbwOdgdjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myDict = dict()\n",
        "  \n",
        "# Creating a list\n",
        "myDict = dict()\n",
        "  \n",
        "# Creating a list\n",
        "valList = ['1', '2', '3']\n",
        "  \n",
        "# Iterating the elements in list\n",
        "for val in valList:\n",
        "    for ele in range(int(val), int(val) + 2): \n",
        "        myDict.setdefault(ele, []).append(val)\n",
        "  \n",
        "print(myDict)\n",
        "\n",
        "  \n",
        "# Iterating the elements in list\n",
        "for val in valList:\n",
        "    for ele in range(int(val), int(val) + 2): \n",
        "        myDict.setdefault(ele, []).append(val)\n",
        "  \n",
        "print(myDict)\n"
      ],
      "metadata": {
        "id": "icC_t-Swh050"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}